<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <title>A Short Cautionary Tale When Backtesting Strategies</title> <div class=franklin-content ><p>&#8287; &#8287;</p> <p><strong><a href="/"><span style="color: black"> cd ..</span></a></strong></p> <p><strong><div style="text-align: right"> 2023-07-15 </div></strong></p> <h1 id=title ><a href="#title" class=header-anchor >A Short Cautionary Tale When Backtesting Strategies</a></h1> <p>back then, someone on Twitter shared a backtest on using 200-day moving averages &#40;200MA&#41; as a buy/sell signal for the S&amp;P500 compared to simply buying and holding it.</p> <img src="/assets/backtesting-tale/robertotalamas_backtest.png"> <img src="/assets/backtesting-tale/robertotalamas_backtest_chart.png"> <img src="/assets/backtesting-tale/robertotalamas_backtest_code.png"> <div style="text-align: center;"> <a href="https://twitter.com/RobertoTalamas/status/1598353728922329089" target=_blank  style="color:grey; font-size: 0.85em;"> https://twitter.com/RobertoTalamas/status/1598353728922329089 </a> </div> <p>looks really good&#33; but a while later, macrocephalopod &#40;a popular account on the quant side of twitter, or fintwit for short&#41; quote-tweeted it.</p> <img src="/assets/backtesting-tale/macrocephalopod_quote.png"> <div style="text-align: center;"> <a href="https://twitter.com/macrocephalopod/status/1598573871271235586" target=_blank  style="color:grey; font-size: 0.85em;"> https://twitter.com/macrocephalopod/status/1598573871271235586 </a> </div> <p>so what went wrong?</p> <h2 id=backtesting_properly_is_hard ><a href="#backtesting_properly_is_hard" class=header-anchor >Backtesting &#40;Properly&#41; is Hard</a></h2> <p>doing data analysis/data mining/statistical inference with market data can seem frictionless. you pull the data, do whatever transforms or comparisons or charts you want, pattern found, edge discovered, model established, and boom: you got a research paper or a empirically tested strategy ready for live trading.</p> <p>but the process belies how little of the overall market dynamic that data is capturing, and that lack of friction means it&#39;s easy for subtle mistakes to creep in to your model.</p> <p>credit where it&#39;s due for OP RobertoTalamas, sharing his code to the public is an admirable move, especially on twitter where cheap dunks are commonplace. and the octopus recognized it too:</p> <img src="/assets/backtesting-tale/macrocephalopod_reply.png"> <div style="text-align: center;"> <a href="https://twitter.com/macrocephalopod/status/1598579432905637888" target=_blank  style="color:grey; font-size: 0.85em;"> https://twitter.com/macrocephalopod/status/1598579432905637888 </a> </div> <p>this is actually relevant to our discussion: part of how to stave off these errors is a workflow that leads you to confront the assumptions behind your model of reality head on, rather than hand-waving it.</p> <p>this involves feedback. in finance, more often than not this takes the form of &quot;finding out&quot; after &quot;f**king around&quot;. it also helps to be surrounded by people who view you in good faith and are willing to give advice.</p> <p>case in point:</p> <img src="/assets/backtesting-tale/jessicanutt96_reply.png"> <div style="text-align: center;"> <a href="https://twitter.com/JessicaNutt96/status/1598583153198776320" target=_blank  style="color:grey; font-size: 0.85em;"> https://twitter.com/JessicaNutt96/status/1598583153198776320 </a> </div> <h2 id=back_to_the_code ><a href="#back_to_the_code" class=header-anchor >Back to the Code</a></h2> <p>so this is a common mistake in simulations: look-ahead bias. it&#39;s when a model uses data that shouldn&#39;t be available at its time. for example, using earnings reports for a period when that data hasn&#39;t been reported &#40;maybe not even determined yet&#41; to the public.</p> <p>in backtesting, this can inflate trading performance since the strategy uses info that other participants in the simulation couldn&#39;t possibly have. or as a mutual jokingly described it: &quot;my alpha is my time machine&quot;.</p> <p>the code&#39;s mistake is on this line. for context, snp&#91;&#39;S&amp;P500&#39;&#93; contains closing prices for the S&amp;P500.</p> <img src="/assets/backtesting-tale/robertotalamas_backtest_code_line.png" style="border-radius:0px;" > <p>as anyone who&#39;s traded stocks will know, you can&#39;t trade using the day&#39;s closing price because... <em>the market&#39;s closed</em>. this bleeds into not one, but two issues with the trade signal:</p> <ul> <li><p>on Day 1, we only get the day&#39;s 200MA after market close, so we have to wait until Day 2 to use it</p> <li><p>on Day 2, we have the 200MA, but our trade signal compares that to the closing price, so... we wait again until Day 2 closes to compare Day 1&#39;s 200MA with Day 2&#39;s closing price. but when do we trade?</p> <li><p>finally on Day 3, we can act on our trade signal.</p> </ul> <p>yes, there is supposed to be a two day lag between signal generation and trade execution. </p> <p>it&#39;s one of the pitfalls of using close-to-close data. if we want to backtest a trade signal that&#39;s actionable on the same day, we&#39;d need more granular data than daily prices. sourcing that may cost money, and it&#39;s harder to process, but yahoo finance&#39;s intraday price data is unreliable, so it&#39;s for you decide whether the cost and operational toll is worth it.</p> <div class=page-foot > Last modified: January 08, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> <script src="/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>